{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_weapon import *\n",
    "from collect_user import *\n",
    "import glob\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loc to loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_to_loc_1 = json.load(open(\"data/loc-to-loc.json\"))\n",
    "loc_to_loc_2 = json.load(open(\"data/loc-to-loc-20200604.json\"))\n",
    "loc_to_loc_3 = json.load(open(\"data/loc-to-loc-20200622.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge all loc_to_loc in a unique dictionary\n",
    "def DictListUpdate( lis1, lis2):\n",
    "    for aLis1 in lis1:\n",
    "        if aLis1 not in lis2:\n",
    "            lis2.append(aLis1)\n",
    "    return lis2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_to_loc= DictListUpdate( loc_to_loc_1,loc_to_loc_2)\n",
    "loc_to_loc_final= DictListUpdate( loc_to_loc,loc_to_loc_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loc to state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_to_state_1 = json.load(open(\"data/loc-to-state.json\"))\n",
    "loc_to_state_2 = json.load(open(\"data/loc-to-state-20200604.json\"))\n",
    "loc_to_state_3 = json.load(open(\"data/loc-to-state-20200622.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_to_state= DictListUpdate( loc_to_state_1,loc_to_state_2)\n",
    "loc_to_state_final= DictListUpdate( loc_to_state,loc_to_state_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loc to county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_to_county = json.load(open(\"data/loc-to-county-20200622.json\"))\n",
    "loc_to_loc = json.load(open(\"data/loc-to-loc-20200622.json\"))\n",
    "loc_to_state = json.load(open(\"data/loc-to-state-20200622.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35092\n",
      "46343\n",
      "84130\n"
     ]
    }
   ],
   "source": [
    "print(len(loc_to_county))\n",
    "print(len(loc_to_state))\n",
    "print(len(loc_to_loc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize loc_to_state_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all the users\n",
    "location=Counter()\n",
    "all_users=set()\n",
    "with open('raw_data/user_info/all_users.lj','w') as _file:\n",
    "    for i in open('raw_data/user_info/Users_info.lj'):\n",
    "        if json.loads(i)['id'] not in all_users:\n",
    "            #location[json.loads(i)['location']]+=1\n",
    "            all_users.add(json.loads(i)['id'])\n",
    "            _file.write(json.dumps(i) + \"\\n\")\n",
    "    for i in open('raw_data/user_info/Users_info_until_November_22.lj'):\n",
    "        #location[json.loads(i)['location']]+=1\n",
    "        if json.loads(i)['id'] not in all_users:\n",
    "            all_users.add(json.loads(i)['id'])\n",
    "            _file.write(json.dumps(i) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing=[]\n",
    "#check those locations we already have\n",
    "for i in location.most_common(15000):\n",
    "    if i[0].lower() in loc_to_loc_final:\n",
    "        continue\n",
    "    else:\n",
    "        missing.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The missing are just junk. The already classified locations are good enouhg.\n",
    "np.unique([i[0] for i in missing])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_from_loc(obj):\n",
    "    try:\n",
    "        complete_loc=loc_to_loc_final[obj]\n",
    "    except:\n",
    "        return False\n",
    "    #loc_to_state\n",
    "    try:\n",
    "        State=loc_to_state_final[complete_loc.lower()]\n",
    "        return State\n",
    "    except:\n",
    "        return False\n",
    "def check_from_state(obj):\n",
    "    try:\n",
    "        State=loc_to_state_final[obj]\n",
    "        return State\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create unique file with users location:\n",
    "ids=set()\n",
    "c=0\n",
    "with open('raw_data/user_info/located_users.lj','w') as _file:\n",
    "    for i in tqdm(all_users):\n",
    "        if i['id'] not in ids:\n",
    "            ids.add(i['id'])\n",
    "            _st=check_from_loc(i['location'].lower())\n",
    "            if _st:\n",
    "                c+=1\n",
    "                _file.write(json.dumps({'user_id':i['id'],'State': _st}) + \"\\n\")\n",
    "            else:\n",
    "                _st=check_from_state(i['location'].lower())\n",
    "                if _st:\n",
    "                    c+=1\n",
    "                    _file.write(json.dumps({'user_id':i['id'],'State': _st}) + \"\\n\")\n",
    "                else:\n",
    "                    continue\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids=set()\n",
    "c=0\n",
    "for i in tqdm(all_users):\n",
    "    if i['id'] not in ids:\n",
    "        ids.add(i['id'])\n",
    "        c+=1\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check=[]\n",
    "for i in  open('raw_data/user_info/located_users.lj'):\n",
    "    check.append(json.loads(i))\n",
    "print('we geolocalized ',len(check)/c,'% of the users')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st=Counter()\n",
    "ids_2=set()\n",
    "for i in check:\n",
    "    if i['user_id'] not in ids_2:\n",
    "        st[i['State']]+=1\n",
    "        ids_2.add(i['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demographic of swing states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SS=['AZ','CO','FL','GA','MI','MN','NV','NH','NC','OH','PA','WI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check=[]\n",
    "swing_users=set()\n",
    "for i in  open('raw_data/user_info/located_users.lj'):\n",
    "    temp=json.loads(i)\n",
    "    if temp['State'] in SS:\n",
    "        check.append(temp)\n",
    "        swing_users.add(temp['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_dict={i['user_id']:i['State'] for i in check}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all the users\n",
    "all_users=[]\n",
    "unique=set()\n",
    "for i in open('raw_data/user_info/Users_info.lj'):\n",
    "    if json.loads(i)['id'] not in unique and json.loads(i)['id'] in swing_users:\n",
    "        all_users.append(json.loads(i))\n",
    "        unique.add(json.loads(i)['id'])\n",
    "for i in open('raw_data/user_info/Users_info_until_November_22.lj'):\n",
    "    if json.loads(i)['id'] not in unique and json.loads(i)['id'] in swing_users:\n",
    "        all_users.append(json.loads(i))\n",
    "        unique.add(json.loads(i)['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('raw_data/user_info/Users_swing_info.lj','w') as _file:\n",
    "    for i in tqdm(all_users):\n",
    "        i['State']=us_dict[i['id']]\n",
    "        _file.write(json.dumps(i) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in open('raw_data/user_info/Users_swing_info.lj'):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.loads(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd + '/home/zhenkun/US_election/raw_data/user_info/Users_swing_info.lj'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=0\n",
    "for i in open('raw_data/user_info/Users_swing_info_fina-error.lj'):\n",
    "    #if json.loads(i)['faces']!='None':\n",
    "    #   i\n",
    "    c+=1\n",
    "    #print(json.loads(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.loads(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = set([\n",
    "     \"202010\",\n",
    "  ])\n",
    "file_names = sorted(Path(\"raw_data\").rglob(\"*.txt\"), reverse=True)\n",
    "set_users = set()\n",
    "for i in open('raw_data/user_info/Final_users_list.lj'):\n",
    "    set_users.add(json.loads(i)['id'])\n",
    "with open(\"raw_data/user_info/Final_users_list.lj\",\"a\") as _file:\n",
    "    for in_name in file_names:\n",
    "        word = in_name.stem.split(\"-\")[-1]\n",
    "        if in_name.parts[1] in months and in_name.parts[2].split('-')[0]>'20200911':\n",
    "            print(in_name)\n",
    "            for line in open(in_name):\n",
    "                try:\n",
    "                    d = json.loads(line.strip())\n",
    "                except Exception:\n",
    "                    print(\"JSON loading error\")\n",
    "                if d[\"user\"][\"id\"] in set_users:\n",
    "                    continue\n",
    "                set_users.add(d[\"user\"][\"id\"])\n",
    "                loc,profile_image_url=None,None\n",
    "                if 'location' in d['user']:\n",
    "                    loc=d[\"user\"][\"location\"]\n",
    "                if \"profile_image_url\" in d[\"user\"]:\n",
    "                    profile_image_url=d[\"user\"][\"profile_image_url\"]\n",
    "                user_info={\"id\":d[\"user\"][\"id\"],\n",
    "                          \"screen_name\":d[\"user\"][\"screen_name\"],\n",
    "                          \"location\": loc,\n",
    "                          \"profile_image_url\":profile_image_url}\n",
    "                _file.write(json.dumps(user_info, ensure_ascii=False) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_users = set()\n",
    "for i in open('raw_data/user_info/Final_users_list.lj'):\n",
    "    set_users.add(json.loads(i)['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##November 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21366664it [02:17, 154987.99it/s]\n"
     ]
    }
   ],
   "source": [
    "c=[]\n",
    "with open('raw_data/user_info/users_county.txt','w') as _file:\n",
    "    for i in tqdm(open('raw_data/user_info/Final_users_list.lj')):\n",
    "        id_=json.loads(i)['id']\n",
    "        loc=json.loads(i)['location']\n",
    "        if loc and loc!='No_location':\n",
    "            loc = loc.lower().replace(\"\\t\", \" \").replace(\"\\n\", \" \")\n",
    "            if loc in loc_to_loc:\n",
    "                w = loc_to_loc[loc].split(\", \")\n",
    "                if w[-1] != \"United States\" or len(w) < 3:\n",
    "                    continue\n",
    "                # print(w)\n",
    "                try:\n",
    "                    county = loc_to_county[loc].split(',')\n",
    "                except:\n",
    "                    c.append(loc)\n",
    "                _file.write( str(id_)+','+ county[0]+','+ county[1].strip().split(' ')[0]+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('raw_data/user_info/users_county.txt',delimiter=',').use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21366664it [02:06, 169438.85it/s]\n"
     ]
    }
   ],
   "source": [
    "coverage=Counter()\n",
    "for i in tqdm(open('raw_data/user_info/Final_users_list.lj')):\n",
    "    id_=json.loads(i)['id']\n",
    "    loc=json.loads(i)['location']\n",
    "    if loc and loc!='No_location':\n",
    "        loc = loc.lower().replace(\"\\t\", \" \").replace(\"\\n\", \" \")\n",
    "        if loc in loc_to_loc:\n",
    "            try:\n",
    "                coverage[loc_to_state[loc_to_loc[loc]]]+=1\n",
    "            except:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5113518"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(list(coverage.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter()"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-b699e82fc628>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloc_to_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloc_to_loc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: None"
     ]
    }
   ],
   "source": [
    "loc_to_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "link='https://www.instagram.com/graphql/query/?query_hash=33ba35852cb50da46f5b5e889df7d159&variables={\"shortcode\":\"CHg0sQJHK22\",\"first\":30}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=requests.get(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.instagram.com/graphql/query/?query_hash=33ba35852cb50da46f5b5e889df7d159&variables={\"shortcode\":\"CHg0sQJHK22\",\"first\":30}'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
